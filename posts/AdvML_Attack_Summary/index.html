<!DOCTYPE html>









<!-- `site.alt_lang` can specify a language different from the UI -->
<html lang="en"
  
>

  <!-- The Head -->

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta
    name="viewport"
    content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover"
  >

  
    

    
  

  

  

  
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="Adversarial Machine Learning Attack papers Summary" />
<meta property="og:locale" content="en" />
<meta name="description" content="In this blog, I summarize the top nine most important papers related to adversarial DNN attacking from the paper which promotes adversarial examples firstly to the advanced attacking methods such as C&amp;W attack, BPDA and EOT." />
<meta property="og:description" content="In this blog, I summarize the top nine most important papers related to adversarial DNN attacking from the paper which promotes adversarial examples firstly to the advanced attacking methods such as C&amp;W attack, BPDA and EOT." />
<link rel="canonical" href="http://c0ldstudy.github.io/posts/AdvML_Attack_Summary/" />
<meta property="og:url" content="http://c0ldstudy.github.io/posts/AdvML_Attack_Summary/" />
<meta property="og:site_name" content="c0ldstudy" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-03-22T00:00:00-07:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Adversarial Machine Learning Attack papers Summary" />
<meta name="twitter:site" content="@JiacenXu" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2020-03-22T00:00:00-07:00","datePublished":"2020-03-22T00:00:00-07:00","description":"In this blog, I summarize the top nine most important papers related to adversarial DNN attacking from the paper which promotes adversarial examples firstly to the advanced attacking methods such as C&amp;W attack, BPDA and EOT.","headline":"Adversarial Machine Learning Attack papers Summary","mainEntityOfPage":{"@type":"WebPage","@id":"http://c0ldstudy.github.io/posts/AdvML_Attack_Summary/"},"url":"http://c0ldstudy.github.io/posts/AdvML_Attack_Summary/"}</script>
<!-- End Jekyll SEO tag -->

  

  <title>Adversarial Machine Learning Attack papers Summary | c0ldstudy
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://realfavicongenerator.net/
-->



<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png">
<link rel="manifest" href="/assets/img/favicons/site.webmanifest">
<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico">
<meta name="apple-mobile-web-app-title" content="c0ldstudy">
<meta name="application-name" content="c0ldstudy">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">


  
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      <link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin>
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://cdn.jsdelivr.net" >
      <link rel="dns-prefetch" href="https://cdn.jsdelivr.net" >
    

    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap">
  

  <!-- GA -->
  

  <!-- Bootstrap -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css">

  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.1/css/all.min.css">

  <link rel="stylesheet" href="/assets/css/style.css">

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.css">
  

  
    <!-- Manific Popup -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css">
  

  <!-- JavaScript -->

  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.1/dist/jquery.min.js"></script>

  
    <!--
  Switch the mode between dark and light.
-->

<script type="text/javascript">
  class ModeToggle {
    static get MODE_KEY() { return "mode"; }
    static get MODE_ATTR() { return "data-mode"; }
    static get DARK_MODE() { return "dark"; }
    static get LIGHT_MODE() { return "light"; }
    static get ID() { return "mode-toggle"; }

    constructor() {
      if (this.hasMode) {
        if (this.isDarkMode) {
          if (!this.isSysDarkPrefer) {
            this.setDark();
          }
        } else {
          if (this.isSysDarkPrefer) {
            this.setLight();
          }
        }
      }

      let self = this;

      /* always follow the system prefers */
      this.sysDarkPrefers.addEventListener('change', () => {
        if (self.hasMode) {
          if (self.isDarkMode) {
            if (!self.isSysDarkPrefer) {
              self.setDark();
            }
          } else {
            if (self.isSysDarkPrefer) {
              self.setLight();
            }
          }

          self.clearMode();
        }

        self.notify();
      });
    } /* constructor() */

    get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); }

    get isSysDarkPrefer() { return this.sysDarkPrefers.matches; }

    get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; }

    get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; }

    get hasMode() { return this.mode != null; }

    get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); }

    /* get the current mode on screen */
    get modeStatus() {
      if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) {
        return ModeToggle.DARK_MODE;
      } else {
        return ModeToggle.LIGHT_MODE;
      }
    }

    setDark() {
      $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE);
    }

    setLight() {
      $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE);
    }

    clearMode() {
      $('html').removeAttr(ModeToggle.MODE_ATTR);
      sessionStorage.removeItem(ModeToggle.MODE_KEY);
    }

    /* Notify another plugins that the theme mode has changed */
    notify() {
      window.postMessage({
        direction: ModeToggle.ID,
        message: this.modeStatus
      }, "*");
    }

    flipMode() {
      if (this.hasMode) {
        if (this.isSysDarkPrefer) {
          if (this.isLightMode) {
            this.clearMode();
          } else {
            this.setLight();
          }
        } else {
          if (this.isDarkMode) {
            this.clearMode();
          } else {
            this.setDark();
          }
        }
      } else {
        if (this.isSysDarkPrefer) {
          this.setLight();
        } else {
          this.setDark();
        }
      }

      this.notify();
    } /* flipMode() */
  } /* ModeToggle */

  const modeToggle = new ModeToggle();
</script>

  
</head>


  <body data-topbar-visible="true">

    <!--
  The Side Bar
-->

<div id="sidebar" class="d-flex flex-column align-items-end">
  <div class="profile-wrapper text-center">
    <div id="avatar">
      <a href="/" class="mx-auto">
        
          
          <img src="/commons/avatar.png" alt="avatar" onerror="this.style.display='none'">
        
      </a>
    </div>

    <div class="site-title">
      <a href="/">c0ldstudy</a>
    </div>
    <div class="site-subtitle font-italic">Absorb what is useful. Reject what is useless. And add what is essentially your own. --- Bruce Lee</div>

  </div><!-- .profile-wrapper -->

  <ul class="w-100">

    <!-- home -->
    <li class="nav-item">
      <a href="/" class="nav-link">
        <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i>
        <span>HOME</span>
      </a>
    </li>
    <!-- the real tabs -->
    
    <li class="nav-item">
      <a href="/categories/" class="nav-link">
        <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>CATEGORIES</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/tags/" class="nav-link">
        <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>TAGS</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/archives/" class="nav-link">
        <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>ARCHIVES</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/about/" class="nav-link">
        <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>ABOUT</span>
      </a>
    </li> <!-- .nav-item -->
    

  </ul> <!-- ul.nav.flex-column -->

  <div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center">

    
      <button class="mode-toggle btn" aria-label="Switch Mode">
        <i class="fas fa-adjust"></i>
      </button>

      
        <span class="icon-border"></span>
      
    

    
      

      
      <a href="https://github.com/c0ldstudy" aria-label="github"
        

        
          target="_blank"
          
        

        

        rel="noopener noreferrer">

        <i class="fab fa-github"></i>
      </a>
      

    
      

      
      <a href="https://twitter.com/JiacenXu" aria-label="twitter"
        

        
          target="_blank"
          
        

        

        rel="noopener noreferrer">

        <i class="fab fa-twitter"></i>
      </a>
      

    
      

      
      <a href="javascript:location.href = 'mailto:' + ['jiacenx','uci.edu'].join('@')" aria-label="email"
        

        

        

        >

        <i class="fas fa-envelope"></i>
      </a>
      

    
      

      
      <a href="/feed.xml" aria-label="rss"
        

        

        

        >

        <i class="fas fa-rss"></i>
      </a>
      

    
      

      
      <a href="https://www.linkedin.com/in/jiacen-xu-021536105/" aria-label="linkedin"
        

        
          target="_blank"
          
        

        

        rel="noopener noreferrer">

        <i class="fab fa-linkedin"></i>
      </a>
      

    

  </div> <!-- .sidebar-bottom -->

</div><!-- #sidebar -->


    <!--
  The Top Bar
-->

<div id="topbar-wrapper">
  <div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4">
    <span id="breadcrumb">

    

    

      

        
          <span>
            <a href="/">
              Home
            </a>
          </span>

        

      

        

      

        

          
            <span>Adversarial Machine Learning Attack papers Summary</span>
          

        

      

    

    </span><!-- endof #breadcrumb -->

    <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i>

    <div id="topbar-title">
      Post
    </div>

    <i id="search-trigger" class="fas fa-search fa-fw"></i>
    <span id="search-wrapper" class="align-items-center">
      <i class="fas fa-search fa-fw"></i>
      <input class="form-control" id="search-input" type="search"
        aria-label="search" autocomplete="off" placeholder="Search...">
    </span>
    <span id="search-cancel" >Cancel</span>
  </div>

</div>


    <div id="main-wrapper" class="d-flex justify-content-center">
      <div id="main" class="container pl-xl-4 pr-xl-4">
        





<div class="row">

  <!-- core -->
  <div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4">
    <div class="post pl-1 pr-1 pl-md-2 pr-md-2">

    

    
      
      
        <!--
  Refactor the HTML structure.
-->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->



<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->



<!-- Change the icon of checkbox -->


<!-- images -->





<!-- Add header for code snippets -->



<!-- Create heading anchors -->





  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    

    

  




<!-- return -->

<h1 data-toc-skip>Adversarial Machine Learning Attack papers Summary</h1>

<div class="post-meta text-muted">
    <!-- published date -->
    <span>
      Posted
      <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em class=""
    data-ts="1584860400"
    data-df="ll"
    data-toggle="tooltip" data-placement="bottom">
  Mar 22, 2020
</em>

    </span>

    <!-- lastmod date -->
    

  

  <div class="d-flex justify-content-between">
    <!-- author(s) -->
    <span>
      

      By

      <em>
      
        <a href="https://twitter.com/JiacenXu">Jiacen (Jason) Xu</a>
      
      </em>
    </span>

    <div>
      <!-- page views -->
      

      <!-- read time -->
      <!--
  Calculate the post's reading time, and display the word count in tooltip
 -->



<!-- words per minute  -->










<!-- return element -->
<span class="readtime" data-toggle="tooltip" data-placement="bottom"
  title="2447 words">
  <em>13 min</em> read</span>

    </div>

  </div> <!-- .d-flex -->

</div> <!-- .post-meta -->

<div class="post-content">
  <p>In this blog, I summarize the top nine most important papers related to adversarial DNN attacking from the paper which promotes adversarial examples firstly to the advanced attacking methods such as C&amp;W attack, BPDA and EOT.</p>

<p>FYI, I find a very useful <a href="https://www.youtube.com/watch?v=KOrHhTSam_o&amp;ab_channel=DS3YouTube">lecture</a> from Prof. Somesh Jha to summarize both the attack and defense on Machine Learning.</p>

<h2 id="1-poisoning-attack-against-support-vector-machines"><span class="mr-2">1. Poisoning attack against support vector machines</span><a href="#1-poisoning-attack-against-support-vector-machines" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>Author-Time-ArXiv: Battista Biggio, Blaine Nelson, Pavel Laskov;ICML 2012; 1206.6389</p>

<p>Keywords: Targeted Attack,</p>

<p>The paper uses the gradient ascent attack on SVM to increase the model’s test error.</p>

<h2 id="2-intriguing-properties-of-neural-networks"><span class="mr-2">2. Intriguing properties of neural networks</span><a href="#2-intriguing-properties-of-neural-networks" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>Author-Time-ArXiv: Ian Goodfellow etc.;ICLR2014; 1312.6199</p>

<p><strong>Key points</strong>:</p>

<ul>
  <li>The <strong>input-space</strong> contains the semantic information in neural networks instead of individual units.</li>
  <li>The input-output mapping is <strong>discontinuous</strong> so the perturbation will cause flips on prediction.</li>
  <li>The perturbation is <strong>transferable</strong>.</li>
  <li>Promoting a targeted attack based on box-constrained L-BFGS which is a matrix form of Newton’s method for optimization.</li>
</ul>

<h3 id="21-introduction"><span class="mr-2">2.1 Introduction</span><a href="#21-introduction" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>There are two counter-intuitive properties of DNN which are the semantic meaning of individual units and the stability of neural network with small perturbations to inputs.</p>

<p>Firstly, they conclude that <strong>the whole activation space</strong> contains the semantic information instead of the last feature layers’ bias used in the researches before. Then, they find a small perturbation is able to change the network’s prediction. They take the <strong>training data which are perturbed by maximizing the prediction error</strong> as <strong><em>adversarial examples</em></strong>. What’s more, they figure out these adversarial examples are able to be transferred to another model trained on a different subset of the dataset. Consequently, the DNN model structure is connected to the data distribution in a non-obvious way.</p>

<h3 id="22-blind-spots-in-neural-networks"><span class="mr-2">2.2 Blind Spots in Neural Networks</span><a href="#22-blind-spots-in-neural-networks" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>The regions in input space mapped by the output unit contain no training examples nearby. These regions share label and the statistical structure of the original inputs. On the other hand, <strong>the smoothness assumption that predictions changed based on perturbations smoothly does not hold</strong>. So the local generalization of the training data are useful for finding adversarial examples in the input space.</p>

<h5 id="formal-description"><span class="mr-2">Formal Description</span><a href="#formal-description" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h5>

<p>Minimize \(c\cdot\vert\vert r\vert\vert_2+loss_f(x+r,l)\) subject to \(x+r\in [0,1]^m\)</p>

<p>\(f:\mathbb{R}^m\rightarrow\{1\dots k\}\) is a classifier mapping image pixel value vectors to a discrete label set.</p>

<p>\(loss_f:\mathbb{R}^m\times\{1\dots k\}\rightarrow\mathbb{R}^+\) is a continuous loss function.</p>

<p>Target label \(l\in\{1\dots k\}\)</p>

<h2 id="3-explaining-and-harnessing-adversarial-examples"><span class="mr-2">3. Explaining and Harnessing Adversarial Examples</span><a href="#3-explaining-and-harnessing-adversarial-examples" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>Author-Time-ArXiv: Ian Goodfellow etc.; ICLR2015;1412.6572</p>

<p><strong>Key Points</strong>:</p>

<ul>
  <li>The main cause of adversarial examples is DNN’s linear nature and the requirement is the <strong>sufficient dimensional inputs</strong>.</li>
  <li>Promoting <strong>Fast Gradient Sign Method</strong> to generate adversarial examples.</li>
  <li>Exploiting <strong>adversarial training</strong> on simple models and DNN models.</li>
</ul>

<h3 id="31-the-linear-explanation-and-perturbation"><span class="mr-2">3.1 The Linear Explanation and Perturbation</span><a href="#31-the-linear-explanation-and-perturbation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>The appearance of adversarial examples is because the DNNs do not learn the true concepts of the whole data to complete the tasks. They are just trained under some discontinuous dataset. Consequently, the linearity of DNN models means that many small perturbations which cannot be detect by eyes will add up to a large change to output.</p>

<p>A simple linear model can have adversarial examples if its input has enough dimensionality which is the reason softmax regression is vulnerable. So the paper promotes <strong>the fast gradient sign method</strong>. It generates adversarial examples to get an optimal max-norm constrained perturbation.</p>

\[\eta=\epsilon sign(\nabla_xJ(\theta,x,y))\]

<p>\(\theta\) is the model parameters. \(x\) is the input while \(y\) is the target(true) label. \(J(\theta,x,y)\) is the loss function and its gradient of \(x\) will represent the perturbation in every direction of \(x\).</p>

<h3 id="32-adversarial-training"><span class="mr-2">3.2 Adversarial Training</span><a href="#32-adversarial-training" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p><strong>More work Needed</strong>: A example to use logistic regression model to train on adversarial examples with weight decay. While the problem is these adversarial examples will be under-fitting.</p>

<p>The paper also uses adversarial training on DNN models. The objective function based on FGSM is an effective regularizer:</p>

\[\tilde J(\theta,x,y)=\alpha J(\theta,x,y)+(1-\alpha)J(\theta,x+\epsilon sign(\nabla_xJ(\theta,{x},y)))\]

<p>It means that the adversarial examples update through training.</p>

<h3 id="33-exploit"><span class="mr-2">3.3 Exploit</span><a href="#33-exploit" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>The adversarial examples appear in a contiguous subspace defined by FGSM. The paper also tries to confirm two hypotheses.</p>

<ul>
  <li>
    <p>Adversarial training provides more constraint on the training process but the improvement is not enough.</p>
  </li>
  <li>
    <p>Averaging several models which aims to wash out adversarial examples has only limited resistance.</p>
  </li>
</ul>

<h3 id="appendix-rubbish-class-examples"><span class="mr-2">Appendix: Rubbish Class Examples</span><a href="#appendix-rubbish-class-examples" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>These examples are degenerate inputs which are meaningless to any category (like noise) but are positive classes in the DNN models. The best result of these examples is prediction is low at any category.</p>

<p><strong>Guess</strong>:</p>

<ol>
  <li>Adversarial Examples exist because DNN cannot restrict all directions in the input space which will lead to a bad accuracy of the validation set.</li>
  <li>We can use constraints of every classes in the input space to promote the robustness of DNN models.</li>
</ol>

<h2 id="4-adversarial-examples-in-the-physical-world"><span class="mr-2">4. Adversarial Examples In the Physical World</span><a href="#4-adversarial-examples-in-the-physical-world" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>Author-Time-ArXiv: Alexey Kurakin etc.; ICLR2017; 1607.02533</p>

<p><strong>Key Points</strong>:</p>

<ul>
  <li>The ML systems in physical world scenarios are vulnerable to adversarial examples.</li>
  <li>Promoting iterative FGSM and Least-likely Class Attack.</li>
  <li>Exploiting the data transformation’s impact on adversarial examples.</li>
</ul>

<h3 id="41-iterative-fast-gradient-sign-method"><span class="mr-2">4.1 Iterative Fast Gradient Sign Method</span><a href="#41-iterative-fast-gradient-sign-method" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>The paper puts forward two iterative FGSMs which are basic iterative method and iterative least-likely class method.</p>

<h4 id="411-basic-iterative-fgsm"><span class="mr-2">4.1.1 Basic iterative FGSM</span><a href="#411-basic-iterative-fgsm" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>The basic iterative method which is a <strong>non-targeted attack</strong> generates adversarial examples as follow:</p>

\[X_0^{adv} = X, X_{N+1}^{adv}=Clip_{X,\epsilon}\{X_N^{adv}+\alpha sign(\nabla_XJ(X_N^{adv},y_{true}))\}\]

<p>\(X\) is a 3-D tensor(width, height, depth) which are integers in the range [0, 255]. \(y_{true}\) is the ground truth. \(J({X},y)\) is cross-entropy cost function of neural network. \(Clip_{X,\epsilon}\{X'\}\) clip the image per-pixel so the result image is \(L_\infty\) \(\epsilon\)-neighborhood of the original image.</p>

\[Clip_{X,\epsilon}\{X'\}(x,y,z)=min\{255, X(x,y,z)+\epsilon,max\{0,X(x,y,z)-\epsilon,X'(x,y,z)\}\}\]

<p>where \({X}(x,y,z)\) is the value of \(z\) of the image \({X}\) at coordinated \((x,y)\).</p>

<h4 id="412-iterative-least-likely-class-method"><span class="mr-2">4.1.2 Iterative least-likely Class Method</span><a href="#412-iterative-least-likely-class-method" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>The iterative least-likely class method, also called <strong>LLC</strong>, is a <strong>targeted attack</strong>. The target label is defined as \(y_{LL}=\underset{x}{\mathrm{argmin}}\{p(y\vert {X})\}\) which presents the least likely class in the whole categories.</p>

\[{X}_0^{adv} = {X}, {X}_{N+1}^{adv}=Clip_{X,\epsilon}\{X_N^{adv}-\alpha sign(\nabla_XJ({X}_N^{adv},y_{LL}))\}\]

<h3 id="42-adversarial-examples-in-real-world"><span class="mr-2">4.2 Adversarial Examples in Real World</span><a href="#42-adversarial-examples-in-real-world" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>The transformations such as blur, noise and JPEG encoding have impact on destructing adversarial examples while changing brightness or contrast is not useful.</p>

<h2 id="5-the-limitations-of-deep-learning-in-adversarial-settings"><span class="mr-2">5. The Limitations of Deep Learning in Adversarial Settings</span><a href="#5-the-limitations-of-deep-learning-in-adversarial-settings" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>Author-Time-ArXiv: Nicolas Papernot etc.; EuroS&amp;P2016; 1511.07528</p>

<p><strong>Key Points</strong>:</p>

<ul>
  <li>Promoting Jacobian-based Saliency Map Attack for acyclic DNN models.</li>
</ul>

<p>In general, the Jacobian-based saliency map constructs the saliency map, the impact of input based on the output’s gradient to find the most important features and then changes them to generate adversarial examples.</p>

<p>The JSM method iterates the following steps when \(F(X^*)\ne Y^*\) and \(\vert\vert \delta_X\vert\vert &lt; \Upsilon\)</p>

<ol>
  <li>
    <p>Forward Derivative of a Deep Neural Network from the input to the layer before output</p>

    <p>A general idea to calculate the forward derivative for a given \(X\): \(\nabla F(X)=\frac{\partial F(X)}{\partial X}=[\frac{\partial F_j(X)}{\partial x_i}]_{i,j\in 1\dots M}\) and the formula is essentially the Jacobian of the function.</p>

    <p>As to the DNN model, the Jacobian can be computed as follow:</p>

\[\frac{\partial F_j(X)}{\partial x_i}=(W_{n+1,j}\cdot\frac{\partial H_n}{\partial x_i})\times\frac{\partial f_{n+1,j}}{\partial x+i}(W_{n+1,j}\cdot H_n+b_{n+1,j})\]

    <p>where the output neuron \(j\) computes the following expression: \(F_j(X)=f_{n+1,j}(W_{n+1,j}\cdot H_n+b_{n+1.j})\)</p>
  </li>
  <li>
    <p>Constructing the Saliency Map \(S(X,t)\) which aims to increase the probabilities of target label \(t\) and decrease the probabilities of other labels.</p>

\[S(X,t)[i]=\begin{cases} 0~if\frac{F_t(X)}{\partial X_i}&lt;0 ~or~ \mathop{\Sigma}_\limits{j\ne t}\frac{F_j(X)}{\partial X_i}&gt;0\\
(\frac{F_t(X)}{\partial X_i})\vert \sum_{j\ne t}\frac{F_j(X)}{\partial X_i}\vert~otherwise\end{cases}\]

    <p>where \(t=\mathop{\arg\max}_\limits{j}F_j(X)\)</p>
  </li>
  <li>
    <p>Modifying \(X_{i_{max}}\) subject to \(i_{max}=\mathop{\arg\max}_\limits{i}S(X,Y^*)[i]\) and adding to the original sample. And the perturbation adding to the input will be set as \(+/-1\) which will increase or decrease the pixel intensities.</p>
  </li>
</ol>

<h2 id="6-towards-evaluating-the-robustness-of-neural-networks"><span class="mr-2">6. Towards Evaluating the Robustness of Neural Networks</span><a href="#6-towards-evaluating-the-robustness-of-neural-networks" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>The details are <a href="/2020/02/C&amp;W_Attack">available</a> on another blog.</p>

<h2 id="7-towards-deep-learning-models-resistant-to-adversarial-attacks"><span class="mr-2">7. Towards Deep Learning Models Resistant to Adversarial Attacks</span><a href="#7-towards-deep-learning-models-resistant-to-adversarial-attacks" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>Author-Time-ArXiv: Aleksander Madry etc.; ICLR2018; 1706.060083</p>

<p><strong>Key Points</strong>:</p>

<ul>
  <li>Promoting Projected Gradient Descent Method(<strong>PGD</strong>).</li>
</ul>

<p>The essence of PGD attack is that a robust DNN model is required to improve a robust attack. So it will improve both the DNN models and adversarial examples at the same time. The paper defines DNN attack as a <strong>min-max</strong> optimization problem instead of a minimization or maximization problem:</p>

<p>\(\mathop{\min}_\limits{\theta} \rho(\theta)\), where \(\rho(\theta)=\mathbb{E}_{(x,y)\sim D}[max_{\delta\in S}L(\theta,x+\delta,y)]\)</p>

<p>\(D\) is the data contribution. \(\mathbb{E}\) is the average error in the course of training. In the inner max part, it will find the specific \(\delta\) to maximize the loss while in the outer min part, it will use different model parameters \(\theta\) to reduce the average error.</p>

<p>The paper uses FGSM and iterative FGSM which is essentially projected gradient descent. The definition of the PGD is displayed as follow:</p>

\[x^{t+1}=\prod_{x+S}(x^t+\alpha sign(\nabla_xL(\theta,x,y)))\]

<p>\(\prod_{x+S}\) means projecting the input in the range of \(x+S\). And the definition of projection can be described as follows:</p>

\[min_x f(x)~s.t.~x\in S\]

\[p^{t+1} = x^t+\alpha sign(\nabla f(x^t)) \\ x^{t+1} = \text{arg} \min_{x \in C} \vert\vert p^{t+1}-x\vert\vert\]

<h2 id="8-obfuscated-gradients-give-a-false-sense-of-security-circumventing-defenses-to-adversarial-examples"><span class="mr-2">8. Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples</span><a href="#8-obfuscated-gradients-give-a-false-sense-of-security-circumventing-defenses-to-adversarial-examples" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>Author-Time-ArXiv: Anish Athalye etc; ICML2018 Best Paper; 1802.00420</p>

<p><strong>Key Points</strong>:</p>

<ul>
  <li>Promoting Backward Pass Differentiable Approximation(<strong>BPDA</strong>) which is useful on obfuscated-gradient-based defenses.</li>
  <li>Displaying that BPDA has a great performance on several gradient-masking based defense methods from ICLR 2018.</li>
</ul>

<p>Basically, the advanced defense method is to break gradient descent by gradient masking. So in the paper, three defense obfuscated gradients are discussed to evaluate the performance of BPDA.</p>

<ul>
  <li>Shattered Gradient</li>
  <li>Stochastic Gradients</li>
  <li>Exploding and Vanishing Gradients</li>
</ul>

<h3 id="81-the-algorithm-of-backward-pass-differentiable-approximation"><span class="mr-2">8.1 The Algorithm of Backward Pass Differentiable Approximation</span><a href="#81-the-algorithm-of-backward-pass-differentiable-approximation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>In general, the BPDA uses the following steps <strong>based on iterative optimization-based attack</strong>(PGD for \(l_\infty\) and C&amp;W attack for \(l_2\)):</p>

<p><strong>Algorithm</strong>:</p>

<p>Let \(f(\cdot)=f^{1\dots j}(\cdot)\) be a neural network and let \(f^i(\cdot)\) be a non-differentiable layer.</p>

<ol>
  <li>To approximate \(\nabla_xf(x)\), find a differentiable approximation identity function \(g(x)\) such that \(g(x)\approx f^i(x)\).</li>
  <li>
    <p>Calculate \(\nabla_xf(x)\) by performing the forward pass through \(f( \cdot )\).</p>
  </li>
  <li>On the backward pass, replacing \(f^i(x)\) with \(g(x)\).</li>
</ol>

<p>In contrast to standard PGD or C&amp;W attack, BPDA requires more iterations of gradient descent.</p>

<p>The paper lists 7 accepted papers from ICLR2018 and takes them as the evaluation to show the great performance of BPDA.</p>

<h3 id="82-gradient-shattering"><span class="mr-2">8.2 Gradient Shattering</span><a href="#82-gradient-shattering" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>At first, it evaluates the non-obfuscated gradients defense like adversarial training and cascade adversarial training which trains a first model to generate adversarial examples and adds them to a second model on the augmented dataset in a single step for efficiency. Since these two defenses are weaker than the later defenses, the paper does not discuss them deeply.</p>

<h4 id="821-thermometer-encoding"><span class="mr-2">8.2.1 Thermometer Encoding</span><a href="#821-thermometer-encoding" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>The definition of thermometer encoding is like that. Given an image \(x\), for each pixel color \(x_{i,j,c}\), the $l$-level thermometer encoding \(\tau(x_{i,k,c})\) is a \(l\)-dimensional vector where \(\tau(x_{i,j,c})_k=1\) if \(x_{i.k.c}&gt;k/l\) and \(0\) otherwise. For example, \(\tau(0.66)=1111110000\) is a 10-level thermometer encoding.</p>

<p>In general, thermometer encoding defense can be taken as a way to cause gradient shattering so it is impossible to perform gradient descent on such kind of DNNs.</p>

<p>As to BPDA, the paper sets \(g(x)=min(max(x_{i,j,c}-k/l,0),1)\) and replaces the backwards pass with \(g(x)\).</p>

<p>Actually \(\tau(x_{i,j,c})_k=floor(g(x))\). The result shows a great performance of BPDA.</p>

<h4 id="822-input-transformations"><span class="mr-2">8.2.2 Input Transformations</span><a href="#822-input-transformations" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>The defense method uses several input transformations to counter adversarial examples such as image cropping and rescaling, bit-depth reduction and JPEG compression.</p>

<p>However, the paper points out that it is possible to bypass each defense respectively and the ensembles of these defenses are not stronger than the sub-defense. The paper uses EOT and BPDA (<em>the paper does not provide details</em>) to circumvent image cropping and rescaling, JPEG compression, image quilting. And the performance of BPDA is also pretty good.</p>

<h4 id="823-local-intrinsic-dimensionality"><span class="mr-2">8.2.3 Local Intrinsic Dimensionality</span><a href="#823-local-intrinsic-dimensionality" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>LID is a general-purpose metric that measures the distance from an input to its neighbors.</p>

<p>The paper discovers LID does not detect high confidence adversarial examples even the adversarial examples are oblivious to the defense.</p>

<h3 id="83-stochastic-gradients"><span class="mr-2">8.3 Stochastic Gradients</span><a href="#83-stochastic-gradients" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<h4 id="831-stochastic-activation-pruning"><span class="mr-2">8.3.1 Stochastic Activation Pruning</span><a href="#831-stochastic-activation-pruning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>SAP randomly drops some neurons of each layer to 0 with probability proportional to their absolute value. Essentially, SAP applies dropout at each layer based on neurons’ weighted distribution. Then these dropped out neurons are retrained and scaled up to retain accuracy.</p>

<p>Implementing SAP decreases clean classification accuracy slightly while increasing robustness. And different levels of drop probability  has similar robustness.</p>

<p>The paper calculates gradient by \(\sum_{i=1}^k\nabla_xf(x)\) where \(k=10\) to achieve useful gradients instead of \(\nabla_xf(x)\). Finally, the result of the attack is good as well.</p>

<h4 id="832-mitigating-through-randomization"><span class="mr-2">8.3.2 Mitigating Through Randomization</span><a href="#832-mitigating-through-randomization" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>The defense adds a randomization layer before the input to the classifier by rescaling and zero-pading the images. The defense dismisses attack by providing lots of choices of randomness.</p>

<p>The paper finds the ensemble attack used by the defense authors overfits to these fixed randomization. So the paper uses EOT and optimize the distribution of transformations to bypass the defense.</p>

<p>The result of the attack is good.</p>

<h3 id="84-vanishing--exploding-gradients"><span class="mr-2">8.4 Vanishing &amp; Exploding Gradients</span><a href="#84-vanishing--exploding-gradients" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<h4 id="841-pixel-defend"><span class="mr-2">8.4.1 Pixel Defend</span><a href="#841-pixel-defend" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>The defense’s authors argue that adversarial examples mainly lie in the low-probability region of the data distribution. So PixelDefend purifies adversarially perturbed images before the classification by using a greedy decoding procedure to approximate finding the highest probability example within an \(\epsilon\)-ball of the input image.</p>

<ol>
  <li>
    <p>Firstly, the joint distribution over all pixels is defined by the product of conditional distributions which originate from <strong>PixelCNN</strong>. \(X=[x_1,x_2,\dots,x_n]\) presents an image.</p>

\[p_{CNN}(X)=\prod_ip_{CNN]}(x_i\vert x_{1:(i-1)})\]

    <p>Every conditional distribution is a multinomial with a 256-way softmax layer based on previous RGB channels as well and each channel variable \(x_i\) takes 0 to 255 distinct values. The higher the joint distribution \(P_{CNN}\), the more suitable it is to the dataset</p>
  </li>
  <li>
    <p>The general distribution of datasets is described by <strong>bits per dimension</strong>. \(I,J,K\) are the size and channel of images.</p>

    <p>\(BPD(X)=-logp_{CNN}(X)/(I\times J\times K\times log2)\).</p>
  </li>
  <li>
    <p>The defense’s authors use hypothesis testing to detect adversarial examples based on distribution.</p>
  </li>
  <li>
    <p>Returning benign images to the training distribution.</p>

\[max_{X^*}p_{CNN}(X^*)\\s.t.\vert\vert X^*-X\vert\vert_{\infty}\le\epsilon_{defend}\]
  </li>
</ol>

<p>The paper avoids computing gradients by approximating gradients with BPDA.</p>

<h4 id="842-defense-gan"><span class="mr-2">8.4.2 Defense-Gan</span><a href="#842-defense-gan" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>Defense-Gan uses GAN to project samples onto the manifold of the generator before classification.</p>

<p>The BPDA attack does not have a good performance on Defense-Gan.</p>

<h2 id="9-synthesizing-robust-adversarial-examples"><span class="mr-2">9. Synthesizing Robust Adversarial Examples</span><a href="#9-synthesizing-robust-adversarial-examples" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>Author-Time-ArXiv: Anish Athalye etc.; ICML2018; 1707.07397</p>

<p><strong>Key Points</strong>:</p>

<ul>
  <li>Promoting Expectation Over Transformation(<strong>EOT</strong>) which proves the impact of a single adversarial example exists over all of the transformations.</li>
  <li>Fabricating the first 3D physical-world adversarial objects to fool classifiers in the real world.</li>
</ul>

<p>The basic approach to generate adversarial examples which aims to maximize the possibility of target label based on the perturbation is not useful when angle and viewpoint changes. Consequently, EOT uses a chosen distribution \(T\) of transformation functions \(t\) to adjust the input \(x\) as  \(t(x)\). The perturbation is also set by the expected effective distance as: \(\delta=\mathbb{E}_{t\sim T}[d(t(x'),t(x))]\). EOT aims to minimize the visual difference between \(t(x')\) and \(t(x)\). So the optimization problem has been:</p>

<p>\(\mathop{\arg\max}\limits_{x'}\mathbb{E}_{t\sim T}[logP(y_t\vert t(x'))]\), subject to \(\mathbb{E}_{t\sim T}[d(t(x'), t(x))]&lt;\epsilon, x\in[0,1]^d\).</p>

<p>The distribution \(T\) can model perceptual distortions like rotation, translation or noising. EOT uses SGD to maximize the objective. In the 2D cases, \(t(x)=Ax+b\) is used for random transformations. EOT also sets distance as \(l_2\) norm in LAB color space which is a perceptually uniform color space in Euclidean distance. So the optimization is set as follow and using PGD to maximize the objective before clipping the set of valid inputs:</p>

\[\mathop{\arg\max}_\limits{x'}\mathbb{E}_{t\sim T}[logP(y_t\vert t(x'))-\lambda\vert\vert LAB(t(x'))-LAB(t(x))\vert\vert_2]\]

</div>

<div class="post-tail-wrapper text-muted">

  <!-- categories -->
  

  <!-- tags -->
  
  <div class="post-tags">
    <i class="fa fa-tags fa-fw mr-1"></i>
      
      <a href="/tags/machine-learning/"
          class="post-tag no-text-decoration" >Machine Learning</a>
      
  </div>
  

  <div class="post-tail-bottom
    d-flex justify-content-between align-items-center mt-3 pt-5 pb-2">
    <div class="license-wrapper">

      

        

        This post is licensed under 
        <a href="https://creativecommons.org/licenses/by/4.0/">
          CC BY 4.0
        </a>
         by the author.

      
    </div>

    <!--
 Post sharing snippet
-->

<div class="share-wrapper">
  <span class="share-label text-muted mr-1">Share</span>
  <span class="share-icons">
    
    
    

    
      
        <a href="https://twitter.com/intent/tweet?text=Adversarial%20Machine%20Learning%20Attack%20papers%20Summary%20-%20c0ldstudy&url=http%3A%2F%2Fc0ldstudy.github.io%2Fposts%2FAdvML_Attack_Summary%2F" data-toggle="tooltip" data-placement="top"
          title="Twitter" target="_blank" rel="noopener" aria-label="Twitter">
          <i class="fa-fw fab fa-twitter"></i>
        </a>
    
      
        <a href="https://www.facebook.com/sharer/sharer.php?title=Adversarial%20Machine%20Learning%20Attack%20papers%20Summary%20-%20c0ldstudy&u=http%3A%2F%2Fc0ldstudy.github.io%2Fposts%2FAdvML_Attack_Summary%2F" data-toggle="tooltip" data-placement="top"
          title="Facebook" target="_blank" rel="noopener" aria-label="Facebook">
          <i class="fa-fw fab fa-facebook-square"></i>
        </a>
    
      
        <a href="https://t.me/share/url?url=http%3A%2F%2Fc0ldstudy.github.io%2Fposts%2FAdvML_Attack_Summary%2F&text=Adversarial%20Machine%20Learning%20Attack%20papers%20Summary%20-%20c0ldstudy" data-toggle="tooltip" data-placement="top"
          title="Telegram" target="_blank" rel="noopener" aria-label="Telegram">
          <i class="fa-fw fab fa-telegram"></i>
        </a>
    

    <i id="copy-link" class="fa-fw fas fa-link small"
        data-toggle="tooltip" data-placement="top"
        title="Copy link"
        data-title-succeed="Link copied successfully!">
    </i>

  </span>
</div>


  </div><!-- .post-tail-bottom -->

</div><!-- div.post-tail-wrapper -->


      
    
    

    </div>
  </div> <!-- #core-wrapper -->

  <!-- panel -->
  <div id="panel-wrapper" class="col-xl-3 pl-2 text-muted">

    <div class="access">
      















  <div id="access-lastmod" class="post">
    <div class="panel-heading">Recently Updated</div>
    <ul class="post-content pl-0 pb-1 ml-1 mt-2">
      
        
        
        
      <li><a href="/posts/LLM_Deploy/">LLM Deploy</a></li>
      
        
        
        
      <li><a href="/posts/Tricks_Summary_2021/">Tricks Summary 2021</a></li>
      
        
        
        
      <li><a href="/posts/Tricks_Summary_2023/">Tricks Summary 2023</a></li>
      
        
        
        
      <li><a href="/posts/GSA/">[SP2024] Understanding and Bridging the Gap Between Unsupervised Network Representation Learning and Security Analytics</a></li>
      
        
        
        
      <li><a href="/posts/PC_attack/">[DSN2023] On Adversarial Robustness of Point Cloud Semantic Segmentation</a></li>
      
    </ul>
  </div> <!-- #access-lastmod -->



      















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <div id="access-tags">
    <div class="panel-heading">Trending Tags</div>
    <div class="d-flex flex-wrap mt-3 mb-1 mr-3">

    
      
      <a class="post-tag" href="/tags/phd/">PhD</a>
    
      
      <a class="post-tag" href="/tags/security/">Security</a>
    
      
      <a class="post-tag" href="/tags/machine-learning/">Machine Learning</a>
    
      
      <a class="post-tag" href="/tags/website/">Website</a>
    
      
      <a class="post-tag" href="/tags/system/">System</a>
    
      
      <a class="post-tag" href="/tags/note/">Note</a>
    
      
      <a class="post-tag" href="/tags/ctf/">CTF</a>
    
      
      <a class="post-tag" href="/tags/conferences/">Conferences</a>
    
      
      <a class="post-tag" href="/tags/design/">Design</a>
    
      
      <a class="post-tag" href="/tags/network/">Network</a>
    

    </div>
  </div>


    </div>

    
      
      



  <div id="toc-wrapper" class="pl-0 pr-4 mb-5">
    <div class="panel-heading pl-3 pt-2 mb-2">Contents</div>
    <nav id="toc"></nav>
  </div>

  <!-- toc.js will be loaded at medium priority -->
  <script src="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.js"></script>


    
  </div>

</div>

<!-- tail -->

<div class="row">
  <div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4 mt-5">
    
      
      <!--
 Recommend the other 3 posts according to the tags and categories of the current post,
 if the number is not enough, use the other latest posts to supplement.
-->

<!-- The total size of related posts  -->


<!-- An random integer that bigger than 0  -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy}  -->








  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  
    
  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  








<!-- Fill with the other newlest posts  -->





  <div id="related-posts" class="mb-2 mb-sm-4">
    <h3 class="pt-2 mb-4 ml-1"
      data-toc-skip>Further Reading</h3>
    <div class="card-deck mb-4">
    
      
      
      <div class="card">
        <a href="/posts/Tensorflow_Learning/">
          <div class="card-body">
            <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em class="small"
    data-ts="1533279600"
    data-df="ll"
    >
  Aug  3, 2018
</em>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>Tensorflow Learning</h3>
            <div class="text-muted small">
              <p>
                





                1. Start Up
The aim of this chapter is to install IPython and tensorflow packages by Anaconda.


  
    Installing Jupyter methods: There are two methods listing on the page, but the first one whic...
              </p>
            </div>
          </div>
        </a>
      </div>
    
      
      
      <div class="card">
        <a href="/posts/Machine_Learning/">
          <div class="card-body">
            <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em class="small"
    data-ts="1555052400"
    data-df="ll"
    >
  Apr 12, 2019
</em>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>Machine Learning Summary</h3>
            <div class="text-muted small">
              <p>
                





                I will keep doing researches in adversarial machine learning, so I need to master the basci knowledge stuff. I want to use this blog to record the important and interesting things.

Some repositori...
              </p>
            </div>
          </div>
        </a>
      </div>
    
      
      
      <div class="card">
        <a href="/posts/Machine-Learning_Tutorial/">
          <div class="card-body">
            <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em class="small"
    data-ts="1603522800"
    data-df="ll"
    >
  Oct 24, 2020
</em>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>Machine Learning Tutorial</h3>
            <div class="text-muted small">
              <p>
                





                In this blog, I would like to introduce how to start your machine learning environment on ubuntu equipped with GPUs . The used tools includes:


  Miniconda: Independent Python Environment.
  Machi...
              </p>
            </div>
          </div>
        </a>
      </div>
    
    </div> <!-- .card-deck -->
  </div> <!-- #related-posts -->


    
      
      <!--
  Navigation buttons at the bottom of the post.
-->

<div class="post-navigation d-flex justify-content-between">
  
  <a href="/posts/Evaluation_of_Adversarial_Example_Defenses/" class="btn btn-outline-primary"
    prompt="Older">
    <p>Evaluation of Adversarial Example Defenses</p>
  </a>
  

  
  <a href="/posts/VS_Code_Plugins/" class="btn btn-outline-primary"
    prompt="Newer">
    <p>Visual Studio Code Plugins</p>
  </a>
  

</div>

    
      
      <!--  The comments switcher -->

  
  <!-- https://giscus.app/ -->
<script type="text/javascript">
  $(function () {
    const origin = "https://giscus.app";
    const iframe = "iframe.giscus-frame";
    const lightTheme = "light";
    const darkTheme = "dark_dimmed";
    let initTheme = lightTheme;

    if ($("html[data-mode=dark]").length > 0
        || ($("html[data-mode]").length == 0
            && window.matchMedia("(prefers-color-scheme: dark)").matches)) {
      initTheme = darkTheme;
    }

    let giscusAttributes = {
      "src": "https://giscus.app/client.js",
      "data-repo": "C0ldstudy/c0ldstudy.github.io",
      "data-repo-id": "MDEwOlJlcG9zaXRvcnkyMzgxNzM1ODU=",
      "data-category": "Announcements",
      "data-category-id": "DIC_kwDODjI9kc4CV58d",
      "data-mapping": "pathname",
      "data-reactions-enabled": "1",
      "data-emit-metadata": "0",
      "data-theme": initTheme,
      "data-input-position": "bottom",
      "data-lang": "",
      "crossorigin": "anonymous",
      "async": ""
    };

    let giscusScript = document.createElement("script");
    Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
    document.getElementById("tail-wrapper").appendChild(giscusScript);

    addEventListener("message", (event) => {
      if (event.source === window && event.data &&
            event.data.direction === ModeToggle.ID) {
        /* global theme mode changed */
        const mode = event.data.message;
        const theme = (mode === ModeToggle.DARK_MODE ? darkTheme : lightTheme);

        const message = {
          setConfig: {
            theme: theme
          }
        };

        const giscus = document.querySelector(iframe).contentWindow;
        giscus.postMessage({ giscus: message }, origin);
      }

    });

  });
</script>



    
  </div>
</div>


      </div>

      <!--
  The Search results
-->
<div id="search-result-wrapper" class="d-flex justify-content-center unloaded">
  <div class="col-12 col-sm-11 post-content">
    <div id="search-hints">
      















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <div id="access-tags">
    <div class="panel-heading">Trending Tags</div>
    <div class="d-flex flex-wrap mt-3 mb-1 mr-3">

    
      
      <a class="post-tag" href="/tags/phd/">PhD</a>
    
      
      <a class="post-tag" href="/tags/security/">Security</a>
    
      
      <a class="post-tag" href="/tags/machine-learning/">Machine Learning</a>
    
      
      <a class="post-tag" href="/tags/website/">Website</a>
    
      
      <a class="post-tag" href="/tags/system/">System</a>
    
      
      <a class="post-tag" href="/tags/note/">Note</a>
    
      
      <a class="post-tag" href="/tags/ctf/">CTF</a>
    
      
      <a class="post-tag" href="/tags/conferences/">Conferences</a>
    
      
      <a class="post-tag" href="/tags/design/">Design</a>
    
      
      <a class="post-tag" href="/tags/network/">Network</a>
    

    </div>
  </div>


    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>


    </div> <!-- #main-wrapper -->

    <!-- The Footer -->

<footer>
    <div class="container pl-lg-4 pr-lg-4">
      <div hidden>
        <div class="github_chart">
          <img src="http://ghchart.rshah.org/409ba5/C0ldstudy" alt="C0ldstudy's Blue Github chart"/>
          <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=PWaejm3rz2TG6HOtwcekX2kM9kPWz2aP6GYhuOVoNpA'></script>
        </div>
      </div>

        <div class="d-flex justify-content-between align-items-center text-muted ml-md-3 mr-md-3">
        <div class="footer-left">
          <p class="mb-0">
            © 2025
            <a href="https://twitter.com/JiacenXu">Jiacen (Jason) Xu</a>.
            
            <span data-toggle="tooltip" data-placement="top"
              title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span>
            
          </p>
        </div>

        <!-- <script  type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=PWaejm3rz2TG6HOtwcekX2kM9kPWz2aP6GYhuOVoNpA&cl=ffffff&w=a"></script> -->
        <div class="footer-right">
          <p class="mb-0"><!-- Using the <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> theme <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>. -->
          </p>
        </div>
      </div>
    </div>
  </footer>


    

    <div id="mask"></div>

    <a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button">
      <i class="fas fa-angle-up"></i>
    </a>

    
      <div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true"
        data-animation="true" data-autohide="false">
        <div class="toast-header">
          <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close">
            <span aria-hidden="true">&times;</span>
          </button>
        </div>
        <div class="toast-body text-center pt-0">
          <p class="pl-2 pr-2 mb-3">A new version of content is available.</p>
          <button type="button" class="btn btn-primary" aria-label="Update">
            Update
          </button>
        </div>
      </div>
    

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->





<script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script>

<script>
SimpleJekyllSearch({
  searchInput: document.getElementById('search-input'),
  resultsContainer: document.getElementById('search-results'),
  json: '/assets/js/data/search.json',
  searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0">  <a href="{url}">{title}</a>  <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">    {categories}    {tags}  </div>  <p>{snippet}</p></div>',
  noResultsText: '<p class="mt-5">Oops! No results found.</p>',
  templateMiddleware: function(prop, value, template) {
    if (prop === 'categories') {
      if (value === '') {
        return `${value}`;
      } else {
        return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
      }
    }

    if (prop === 'tags') {
      if (value === '') {
        return `${value}`;
      } else {
        return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
      }
    }
  }
});
</script>


    <!-- JS selector for site. -->

<!-- layout specified -->


  



  <!-- image lazy-loading & popup & clipboard -->
  

  







  
    

    

  



  
    

    

  



  
    

    

  




  <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/lazysizes@5.3.2/lazysizes.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js"></script>





  

  

  







  
    

    

  



  
    

    

  



  
    

    

  



  
    

    

  




  <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1.11.6/dayjs.min.js,npm/dayjs@1.11.6/locale/en.min.js,npm/dayjs@1.11.6/plugin/relativeTime.min.js,npm/dayjs@1.11.6/plugin/localizedFormat.min.js"></script>







<script defer src="/assets/js/dist/post.min.js"></script>



<!-- commons -->

<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"></script>




  </body>

</html>

